{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f61f35e8",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d4ae20",
   "metadata": {},
   "source": [
    "#### 1. Nustatykite vektorinius ryšius tarp Jūsų sugalvotų dviejų sinonimų. Žodžių vektorizavimui naudokite Word2vec. Kosinusų atstumui tarp dviejų vektorių paskaičiuoti naudokite du būdus: SpaCy bibliotekos funkciją \"similarity\" ir Scipy bibliotekos funkciją \"cosine\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31d809fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy similarity: 0.6269938541015648\n",
      "Cosine similarity: 0.5454052152971965\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from gensim import downloader as gensim_api\n",
    "from scipy import spatial\n",
    "\n",
    "nlp_gensim = gensim_api.load(\"word2vec-google-news-300\")\n",
    "nlp_spacy = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# getting vectors\n",
    "word_1 = \"journal\"\n",
    "word_2 = \"magazine\"\n",
    "word_1_vect = nlp_gensim.get_vector(word_1)\n",
    "word_2_vect = nlp_gensim.get_vector(word_2)\n",
    "\n",
    "# calculating similarity using spacy library\n",
    "similarity = nlp_spacy(word_1).similarity(nlp_spacy(word_2))\n",
    "print(f\"Spacy similarity: {similarity}\")\n",
    "\n",
    "# get similarity by calculating cosine between vectors\n",
    "cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n",
    "similarity = cosine_similarity(word_1_vect, word_2_vect)\n",
    "print(f\"Cosine similarity: {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962729ad",
   "metadata": {},
   "source": [
    "#### 2. Nustatykite vektorinius ryšius tarp Jūsų sugalvotų dviejų antonimų. Teksto vektorizavimui naudokite TF-IDF. Dokumentų rinkinį, susidedanti iš kelių vieno sakinio tekstų sukurkite patys\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c25508a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.605761057726931\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "sentences = [\n",
    "    \"The master of the banquet tasted the water that had been turned into wine.\",\n",
    "    \"There are many countries that do not have access to clean water.\",\n",
    "    \"This girl is on fire.\"\n",
    "    \"I feel that I'm on fire.\"\n",
    "    \"The antonym of water is fire.\"\n",
    "    \"They tried to extinguish fire with water, but they didn't succeed.\",\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(sentences)\n",
    "\n",
    "word_1 = \"fire\"\n",
    "word_2 = \"water\"\n",
    "\n",
    "word_1_idx = vectorizer.vocabulary_[word_1]\n",
    "word_2_idx = vectorizer.vocabulary_[word_2]\n",
    "\n",
    "word_1_vect = X[:, word_1_idx].todense().A1\n",
    "word_2_vect = X[:, word_2_idx].todense().A1\n",
    "\n",
    "# calculating cosine similarity\n",
    "cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n",
    "similarity = cosine_similarity(word_1_vect, word_2_vect)\n",
    "print(f\"Cosine similarity: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c87b1f",
   "metadata": {},
   "source": [
    "#### 3. Nustatykite vektorinius ryšius tarp 2-am uždaviniui sugalvotų dviejų antonimų. Teksto vektorizavimui naudokite TF-IDF. Naudokite vieną iš bibliotekų pateiktų pavyzdinių duomenų rinkinių (pvz. Brown corpus) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8df58afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.8364119356634941\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# nltk.download(\"brown\")\n",
    "\n",
    "word_1 = \"fire\"\n",
    "word_2 = \"water\"\n",
    "\n",
    "documents = [' '.join(brown.words(categories=category)) for\n",
    "category in brown.categories()]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "word_1_idx = vectorizer.vocabulary_[word_1]\n",
    "word_2_idx = vectorizer.vocabulary_[word_2]\n",
    "\n",
    "word_1_vect = X[:, word_1_idx].todense().A1\n",
    "word_2_vect = X[:, word_2_idx].todense().A1\n",
    "\n",
    "# calculating cosine similarity\n",
    "cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n",
    "similarity = cosine_similarity(word_1_vect, word_2_vect)\n",
    "print(f\"Cosine similarity: {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbc1aa5",
   "metadata": {},
   "source": [
    "#### 4. Nustatykite vektorinius ryšius tarp Jūsų sugalvoto hipernimo ir jo dviejų hiponimų. Teksto vektorizavimui naudokite žodžių maišą. Rezultatą pateikite lentelės pavidalu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c6c8b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<table>         <tr>             <th></th>             <th>clothing</th>             <th>jacket</th>             <th>pants</th>         </tr>         <tr>             <th>clothing</th>             <td>1.0</td>             <td>0.4538253483538691</td>             <td>0.34641016151377535</td>         </tr>         <tr>             <th>jacket</th>             <td>0.4538253483538691</td>             <td>1.0</td>             <td>0.7890260177824231</td>         </tr>         <tr>             <th>pants</th>             <td>0.34641016151377535</td>             <td>0.7890260177824231</td>             <td>1.0</td>         </tr>     </table>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "hypernym = \"clothing\"\n",
    "hiponym_1 = \"jacket\"\n",
    "hiponym_2 =  \"pants\"\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "hypernym_idx = vectorizer.vocabulary_[hypernym]\n",
    "hiponym_1_idx = vectorizer.vocabulary_[hiponym_1]\n",
    "hiponym_2_idx = vectorizer.vocabulary_[hiponym_2]\n",
    "\n",
    "hypernym_vect = X[:, hypernym_idx].todense().A1\n",
    "hiponym_1_vect= X[:, hiponym_1_idx].todense().A1\n",
    "hiponym_2_vect= X[:, hiponym_2_idx].todense().A1\n",
    "\n",
    "# calculating cosine similarity\n",
    "cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n",
    "display(Markdown(f\"<table> \\\n",
    "        <tr> \\\n",
    "            <th></th> \\\n",
    "            <th>{hypernym}</th> \\\n",
    "            <th>{hiponym_1}</th> \\\n",
    "            <th>{hiponym_2}</th> \\\n",
    "        </tr> \\\n",
    "        <tr> \\\n",
    "            <th>{hypernym}</th> \\\n",
    "            <td>{cosine_similarity(hypernym_vect, hypernym_vect)}</td> \\\n",
    "            <td>{cosine_similarity(hypernym_vect, hiponym_1_vect)}</td> \\\n",
    "            <td>{cosine_similarity(hypernym_vect, hiponym_2_vect)}</td> \\\n",
    "        </tr> \\\n",
    "        <tr> \\\n",
    "            <th>{hiponym_1}</th> \\\n",
    "            <td>{cosine_similarity(hypernym_vect, hiponym_1_vect)}</td> \\\n",
    "            <td>{cosine_similarity(hiponym_1_vect, hiponym_1_vect)}</td> \\\n",
    "            <td>{cosine_similarity(hiponym_1_vect, hiponym_2_vect)}</td> \\\n",
    "        </tr> \\\n",
    "        <tr> \\\n",
    "            <th>{hiponym_2}</th> \\\n",
    "            <td>{cosine_similarity(hypernym_vect, hiponym_2_vect)}</td> \\\n",
    "            <td>{cosine_similarity(hiponym_1_vect, hiponym_2_vect)}</td> \\\n",
    "            <td>{cosine_similarity(hiponym_2_vect, hiponym_2_vect)}</td> \\\n",
    "        </tr> \\\n",
    "    </table>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989f0bbf",
   "metadata": {},
   "source": [
    "#### 5. Nustatykite vektorinius ryšius tarp Jūsų sugalvoto holonimo ir jo dviejų meronimu. Rezultatą pateikite lentelės pavidalu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0ae7cc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<table>         <tr>             <th></th>             <th>tree</th>             <th>leaf</th>             <th>trunk</th>         </tr>         <tr>             <th>tree</th>             <td>1.0</td>             <td>0.6433023760006604</td>             <td>0.5474891952751688</td>         </tr>         <tr>             <th>leaf</th>             <td>0.6433023760006604</td>             <td>1.0</td>             <td>0.5025289995244617</td>         </tr>         <tr>             <th>trunk</th>             <td>0.5474891952751688</td>             <td>0.5025289995244617</td>             <td>1.0</td>         </tr>     </table>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "holonym = \"tree\"\n",
    "meronym_1 = \"leaf\"\n",
    "meronym_2 =  \"trunk\"\n",
    "\n",
    "display(Markdown(f\"<table> \\\n",
    "        <tr> \\\n",
    "            <th></th> \\\n",
    "            <th>{holonym}</th> \\\n",
    "            <th>{meronym_1}</th> \\\n",
    "            <th>{meronym_2}</th> \\\n",
    "        </tr> \\\n",
    "        <tr> \\\n",
    "            <th>{holonym}</th> \\\n",
    "            <td>{nlp(holonym).similarity(nlp(holonym))}</td> \\\n",
    "            <td>{nlp(holonym).similarity(nlp(meronym_1))}</td> \\\n",
    "            <td>{nlp(holonym).similarity(nlp(meronym_2))}</td> \\\n",
    "        </tr> \\\n",
    "        <tr> \\\n",
    "            <th>{meronym_1}</th> \\\n",
    "            <td>{nlp(holonym).similarity(nlp(meronym_1))}</td> \\\n",
    "            <td>{nlp(meronym_1).similarity(nlp(meronym_1))}</td> \\\n",
    "            <td>{nlp(meronym_1).similarity(nlp(meronym_2))}</td> \\\n",
    "        </tr> \\\n",
    "        <tr> \\\n",
    "            <th>{meronym_2}</th> \\\n",
    "            <td>{nlp(holonym).similarity(nlp(meronym_2))}</td> \\\n",
    "            <td>{nlp(meronym_1).similarity(nlp(meronym_2))}</td> \\\n",
    "            <td>{nlp(meronym_2).similarity(nlp(meronym_2))}</td> \\\n",
    "        </tr> \\\n",
    "    </table>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
