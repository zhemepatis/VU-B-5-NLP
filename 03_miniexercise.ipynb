{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\"> Uždavinių atlikimui naudokite tekstą esantį dokumente `tekstas1.txt`. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Atspausdinkite antro sakinio kalbos vienetus, Pos žymas, smulkiagretes POS žymas ir jų aprašymą (angl. token text, the POS tag, the fine-grained TAG tag, and the description of the fine-grained tag). Uždavinį atlikite su spaCy biblioteka "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On              ADP             IN              conjunction, subordinating or preposition\n",
      "the             DET             DT              determiner     \n",
      "way             NOUN            NN              noun, singular or mass\n",
      "they            PRON            PRP             pronoun, personal\n",
      "had             VERB            VBD             verb, past tense\n",
      "to              PART            TO              infinitival \"to\"\n",
      "cross           VERB            VB              verb, base form\n",
      "a               DET             DT              determiner     \n",
      "stream          NOUN            NN              noun, singular or mass\n",
      ".               PUNCT           .               punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "with open(\"data/03_data.txt\") as file:\n",
    "    text  = file.read()\n",
    "\n",
    "# loading model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(text)\n",
    "\n",
    "# getting 2nd sentence\n",
    "sentences = [item.__str__() for item in doc.sents]\n",
    "sentence_doc = nlp(sentences[1])\n",
    "\n",
    "# getting tokens, their POS, tags\n",
    "for token in sentence_doc:\n",
    "    token_str = token.__str__()\n",
    "    pos = token.pos_.__str__()\n",
    "    tag = token.tag_\n",
    "    print(f\"{token_str:15} {pos:15} {tag:15} {spacy.explain(tag):15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Pateikite dokumento POS žymų dažnumo sąrašą"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.ADJ  : 10\n",
      "85.ADP  : 9\n",
      "86.ADV  : 9\n",
      "87.AUX  : 5\n",
      "89.CCONJ: 6\n",
      "90.DET  : 32\n",
      "92.NOUN : 39\n",
      "93.NUM  : 1\n",
      "94.PART : 8\n",
      "95.PRON : 7\n",
      "96.PROPN: 1\n",
      "97.PUNCT: 13\n",
      "98.SCONJ: 1\n",
      "100.VERB : 24\n",
      "103.SPACE: 7\n"
     ]
    }
   ],
   "source": [
    "counts = doc.count_by(spacy.attrs.POS)\n",
    "for (key, freq) in sorted(counts.items()):\n",
    "    print(f\"{key}.{doc.vocab[key].text:5}: {freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Atspausdinkite visus tekste esančius būdvardžius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Foolish, light, happy, same, next, same, lighter, dampened, heavy, happy]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for token in doc:\n",
    "    if token.pos_ == \"ADJ\":\n",
    "        result.append(token)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Atspausdinkite visus tekste esančius prielinksnius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[suddenly, also, hence, very, Then, Again, still, very, anymore]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for token in doc:\n",
    "    if token.pos_ == \"ADV\":\n",
    "        result.append(token)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Koks procentas tokenų yra veiksmažodžiai?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.95%\n"
     ]
    }
   ],
   "source": [
    "token_num = len(doc)\n",
    "print(f\"{round(counts[100] / token_num * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Atspausdinkite 2-ro sakinio tokenus ir POS žymas. Uždavinį atlikite su NLTK biblioteka "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color= blue> https://www.nltk.org/book/ch05.html </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/rink/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/rink/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('On', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('way', 'NN'),\n",
       " ('they', 'PRP'),\n",
       " ('had', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('cross', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('stream', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "# getting sentence\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "sentence = sentences[1]\n",
    "\n",
    "# getting token POS\n",
    "words = nltk.word_tokenize(sentence)\n",
    "nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Iš turimo teksto (t.y. viso nuskaityto teksto) pašalinkite visus veiksmažodžius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Foolish Donkey A salt seller to the salt bag on his donkey to the market every day . On the way they to a stream . One day the donkey suddenly down the stream and the salt bag also into the water . The salt in the water and hence the bag very light to . The donkey happy . Then the donkey to the same trick every day . The salt seller to the trick and to a lesson to it . The next day he a cotton bag on the donkey . it the same trick hoping that the cotton bag would still lighter . But the dampened cotton very heavy to and the donkey . It a lesson . It not the trick anymore after that day , and the seller happy .\n"
     ]
    }
   ],
   "source": [
    "words = nltk.word_tokenize(text);\n",
    "word_pos_pairs = nltk.pos_tag(words)\n",
    "\n",
    "not_verbs = []\n",
    "for (word, pos) in word_pos_pairs:\n",
    "    if not pos.startswith('VB'):\n",
    "        not_verbs.append(word)\n",
    "\n",
    "result = \" \".join(not_verbs)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
